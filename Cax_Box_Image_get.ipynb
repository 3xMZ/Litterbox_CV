{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "import serial\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sb\n",
    "\n",
    "from collections import OrderedDict\n",
    "# from labjack import ljm\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from typing import Tuple\n",
    "\n",
    "from skimage.metrics import structural_similarity as compare_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def take_picture(cam_ID: int, width: int, height: int, name_ID: int, crop: bool = False):\n",
    "    cap = cv2.VideoCapture(cam_ID)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    path = '/home/michael/Cax_Box_Pics/temp'\n",
    "    if cap.isOpened():\n",
    "        for i in range(20):\n",
    "            _,_ = cap.read()\n",
    "        ret, frame = cap.read()\n",
    "        if crop:\n",
    "            crop_img = frame[0:-100, 150:-75]\n",
    "            cv2.imwrite(\n",
    "                os.path.join(path , \"litterbox_cropped_\" + str(name_ID) + \".png\"),\n",
    "                crop_img)\n",
    "        else:\n",
    "            cv2.imwrite(\n",
    "                os.path.join(path , \"litterbox_\" + str(name_ID) + \".png\"),\n",
    "                frame)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return frame\n",
    "\n",
    "# def toggle_fan(handle, fan_state: int) -> None:\n",
    "#     ljm.eWriteName(handle, \"FIO3\", fan_state)\n",
    "\n",
    "def toggle_fan(fan_state: int) -> None:\n",
    "    s = serial.Serial('/dev/ttyACM0', 9600)\n",
    "    if fan_state == 0:\n",
    "        s.write(b'fan_off')\n",
    "        s.write(b'\\n')\n",
    "    elif fan_state == 1:\n",
    "        s.write(b'fan_on')\n",
    "        s.write(b'\\n')\n",
    "    s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath: str):\n",
    "    \"\"\" Reload a saved .pth model.\"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "\n",
    "    if checkpoint['arch'] == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Architecture not recognized.\")\n",
    "\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    classifier = nn.Sequential(\n",
    "        OrderedDict([('fc1', nn.Linear(25088, 5000)),\n",
    "                    ('relu', nn.ReLU()),\n",
    "                    ('drop', nn.Dropout(p=0.5)),\n",
    "                    ('fc2', nn.Linear(5000, 102)),\n",
    "                    ('output', nn.LogSoftmax(dim=1))]))\n",
    "    model.classifier = classifier\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def process_image(image_path: str) -> np.array:\n",
    "    ''' Image preprocessor for inference.\n",
    "\n",
    "        Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "\n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    pil_image = Image.open(image_path)\n",
    "\n",
    "    # Resize\n",
    "    if pil_image.size[0] > pil_image.size[1]:\n",
    "        pil_image.thumbnail((5000, 256))\n",
    "    else:\n",
    "        pil_image.thumbnail((256, 5000))\n",
    "\n",
    "    # Crop\n",
    "    left_margin = (pil_image.width-224)/2\n",
    "    bottom_margin = (pil_image.height-224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    top_margin = bottom_margin + 224\n",
    "\n",
    "    pil_image = pil_image.crop((left_margin, bottom_margin,\n",
    "                                right_margin, top_margin))\n",
    "\n",
    "    # Normalize\n",
    "    np_image = np.array(pil_image)/255\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np_image - mean) / std\n",
    "\n",
    "    # PyTorch expects the color channel to be the first dimension but it's the\n",
    "    # third dimension in the PIL image and Numpy array\n",
    "    # Color channel needs to be first; retain the order of the other two\n",
    "    # dimensions.\n",
    "    np_image = np_image.transpose((2, 0, 1))\n",
    "\n",
    "    return np_image\n",
    "\n",
    "\n",
    "def predict(image_path, model, topk: int = 3):\n",
    "    ''' Predict the class of an image using trained deep learning model.'''\n",
    "\n",
    "    image = process_image(image_path)\n",
    "\n",
    "    # Convert image to PyTorch tensor first\n",
    "    \n",
    "    #CUDA\n",
    "    # image = torch.from_numpy(image).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    #CPU\n",
    "    image = torch.from_numpy(image).type(torch.FloatTensor)\n",
    "\n",
    "    # Returns a new tensor with a dimension of size one inserted\n",
    "    # at the specified position.\n",
    "    image = image.unsqueeze(0)\n",
    "    output = model.forward(image)\n",
    "    probabilities = torch.exp(output)\n",
    "\n",
    "    # Probabilities and the indices of those probabilities\n",
    "    # corresponding to the classes\n",
    "    top_prob, top_ind = probabilities.topk(topk)\n",
    "\n",
    "    # Convert to lists\n",
    "    top_prob = top_prob.detach().type(torch.FloatTensor).numpy().tolist()[0]\n",
    "    top_ind = top_ind.detach().type(torch.FloatTensor).numpy().tolist()[0]\n",
    "\n",
    "    # Convert topk_indices to the actual class labels using class_to_idx\n",
    "    # Invert the dictionary so you get a mapping from index to class.\n",
    "\n",
    "    idx_to_class = {value: key for key, value in model.class_to_idx.items()}\n",
    "    top_classes = [idx_to_class[index] for index in top_ind]\n",
    "\n",
    "    return top_prob, top_classes\n",
    "\n",
    "def _check_image(image_path: str, inf_model):\n",
    "    probs, classes = predict(image_path, model)\n",
    "    print(classes)\n",
    "    print(probs)\n",
    "    print('\\n')\n",
    "    return classes[0], float(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "path = '/home/michael/Cax_Box_Pics/temp'\n",
    "config_path = '/home/michael/Cax_Box_Pics'\n",
    "config_path = os.path.join(config_path , \"cax_box_config\" + \".conf\")\n",
    "#model = load_checkpoint('May_22_2021_basic_vgg.pth')\n",
    "model = load_checkpoint('Sep_12_2021_basic_vgg.pth')\n",
    "# handle = ljm.openS(\"T7\", \"USB\", \"ANY\")\n",
    "toggle_fan(0)\n",
    "\n",
    "with open(config_path) as f:\n",
    "    image_counter = [line for line in f]\n",
    "\n",
    "image_counter = int(image_counter[0])\n",
    "image_last = take_picture(0, 640, 480, image_counter, crop = True)\n",
    "gray_last = cv2.cvtColor(image_last, cv2.COLOR_BGR2GRAY)\n",
    "previous_state = [\"0\"]\n",
    "default_wait_time = 30\n",
    "extended_wait_time = 300\n",
    "wait_time = default_wait_time\n",
    "\n",
    "save_counters = {\"0\": 1, \"1\": 1, \"2\": 1}\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        image = take_picture(0, 640, 480, image_counter, crop = True)\n",
    "        image_path = os.path.join(path , \"litterbox_cropped_\"\n",
    "                                  + str(image_counter) + \".png\")\n",
    "        f = open(config_path, \"w\")\n",
    "        f.write(str(image_counter + 1))\n",
    "        f.close()\n",
    "\n",
    "        box_state_inf, box_state_prob = _check_image(image_path, model)\n",
    "        save_counters[box_state_inf] += 1\n",
    "\n",
    "        if box_state_inf == \"0\" and save_counters[\"0\"] % 20 == 0:\n",
    "            shutil.copy(image_path, 'inf//' + str(box_state_inf))\n",
    "        elif box_state_inf == \"1\" and save_counters[\"1\"] % 20 == 0:\n",
    "            shutil.copy(image_path, 'inf//' + str(box_state_inf))\n",
    "        elif box_state_inf == \"2\":\n",
    "            shutil.copy(image_path, 'inf//' + str(box_state_inf))\n",
    "        elif box_state_inf == \"3\":\n",
    "            pass\n",
    "\n",
    "        gray_current = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        score, diff = compare_ssim(gray_last, gray_current, full=True)\n",
    "\n",
    "        print(\"Box State Probabaility: {:.3f} \\n\".format(box_state_prob))\n",
    "        print(\"Structural Diff: {:.2f} \\n\".format(score))\n",
    "        print(\"Prev state:  {}, Current State: {}\".format(previous_state[0], box_state_inf))\n",
    "\n",
    "        if box_state_prob >= 0.90 and score <= 0.90:\n",
    "            if box_state_inf == \"1\" and previous_state[0] == \"0\":\n",
    "                toggle_fan(1)\n",
    "                previous_state[0] = \"1\"\n",
    "                wait_time = extended_wait_time\n",
    "            elif box_state_inf == \"0\" and previous_state[0] == \"1\":\n",
    "                previous_state[0] = \"0\"\n",
    "                wwait_time = extended_wait_time\n",
    "            if box_state_inf == \"2\":\n",
    "                previous_state[0] = \"0\"\n",
    "                wait_time = default_wait_time\n",
    "        gray_last = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        os.remove(image_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    image_counter += 1\n",
    "    time.sleep(wait_time)\n",
    "    toggle_fan(0)\n",
    "    if image_counter % 10 == 0:\n",
    "        print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toggle_fan(0)\n",
    "! ls /dev | grep ttyACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toggle_fan(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
